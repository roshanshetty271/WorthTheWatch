"""
Worth the Watch? â€” FastAPI Application
"Should I stream this? The internet decides."
"""

import gc
import logging
import secrets
from contextlib import asynccontextmanager
from fastapi import FastAPI, Depends, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, desc

from app.config import get_settings
from app.database import init_db, get_db
from app.models import Movie, Review, SearchEvent  # noqa: F401
from app.routers import movies, search, versus, nowplaying, discover
from app.jobs.daily_sync import run_daily_sync
from app.schemas import HealthCheck

settings = get_settings()

# â”€â”€â”€ Logging â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(name)s | %(message)s",
)
logger = logging.getLogger(__name__)


# â”€â”€â”€ Lifespan â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Startup: create tables. Shutdown: cleanup."""
    logger.info("ğŸ¬ Worth the Watch? â€” Starting up...")
    await init_db()
    logger.info("âœ… Database initialized")
    
    from app.services.tmdb import tmdb_service
    import asyncio
    asyncio.create_task(tmdb_service.refresh_popular_cache())
    
    yield
    logger.info("ğŸ‘‹ Shutting down...")


# â”€â”€â”€ App â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

app = FastAPI(
    title="Worth the Watch? API",
    description="AI-powered movie review aggregation. The internet decides.",
    version="1.0.0",
    lifespan=lifespan,
    docs_url="/docs" if settings.ENVIRONMENT == "development" else None,
    redoc_url="/redoc" if settings.ENVIRONMENT == "development" else None,
    openapi_url="/openapi.json" if settings.ENVIRONMENT == "development" else None,
)


# â”€â”€â”€ Global Error Handler â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SECURITY: Never leak tracebacks, table names, or file paths to clients.

@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    logger.error(f"Unhandled error on {request.method} {request.url.path}: {exc}", exc_info=True)
    return JSONResponse(
        status_code=500,
        content={"detail": "Internal server error"},
    )


# CORS â€” allow frontend origins
origins = [o.strip() for o in settings.ALLOWED_ORIGINS.split(",")]
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# â”€â”€â”€ Routers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

app.include_router(movies.router, prefix="/api/movies", tags=["movies"])
app.include_router(search.router, prefix="/api", tags=["search"])
app.include_router(versus.router, prefix="/api/versus", tags=["versus"])
app.include_router(nowplaying.router, prefix="/api/nowplaying", tags=["nowplaying"])
app.include_router(discover.router, prefix="/api/discover", tags=["discover"])


# â”€â”€â”€ Sitemap (SEO) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@app.get("/api/sitemap")
async def get_sitemap_data(db: AsyncSession = Depends(get_db)):
    """Returns all reviewed movie IDs for sitemap generation."""
    result = await db.execute(
        select(Movie.tmdb_id, Movie.title, Review.generated_at)
        .join(Review)
        .order_by(desc(Review.generated_at))
    )
    rows = result.all()
    return [
        {"tmdb_id": r.tmdb_id, "title": r.title, "updated_at": r.generated_at.isoformat()}
        for r in rows
    ]


# â”€â”€â”€ Health Check â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@app.get("/health", response_model=HealthCheck)
async def health_check(
    check_services: bool = False,
    secret: str = "",
    db: AsyncSession = Depends(get_db),
):
    if not check_services:
        return HealthCheck(status="ok")
    
    if not secrets.compare_digest(secret, settings.CRON_SECRET):
        raise HTTPException(status_code=403, detail="Invalid secret for deep check")

    health_status = {
        "status": "ok", 
        "database": "unknown",
        "tmdb": "unknown",
        "llm": "unknown",
        "serper": "unknown"
    }

    try:
        await db.execute(select(1))
        health_status["database"] = "connected"
    except Exception as e:
        logger.error(f"Health DB fail: {e}")
        health_status["database"] = "disconnected"
        health_status["status"] = "degraded"

    try:
        from app.services.tmdb import tmdb_service
        await tmdb_service.get_movie_details(550)
        health_status["tmdb"] = "connected"
    except Exception as e:
        logger.error(f"Health TMDB fail: {e}")
        health_status["tmdb"] = "disconnected"
        health_status["status"] = "degraded"

    try:
        if settings.OPENAI_API_KEY or settings.DEEPSEEK_API_KEY:
             from app.services.llm import llm_client, llm_model
             await llm_client.chat.completions.create(
                 model=llm_model,
                 messages=[{"role": "user", "content": "hi"}],
                 max_tokens=1
             )
             health_status["llm"] = "connected"
        else:
             health_status["llm"] = "not_configured"
    except Exception as e:
        logger.error(f"Health LLM fail: {e}")
        health_status["llm"] = "error"
        health_status["status"] = "degraded"

    try:
        if settings.SERPER_API_KEY:
            from app.services.serper import serper_service
            await serper_service.search_reviews("test", "2024", "movie")
            health_status["serper"] = "connected"
        else:
            health_status["serper"] = "not_configured"
    except Exception as e:
        logger.error(f"Health Serper fail: {e}")
        health_status["serper"] = "error"
        health_status["status"] = "degraded"

    return HealthCheck(**health_status)


# â”€â”€â”€ Cron Endpoint â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@app.post("/api/cron/daily")
async def cron_daily(
    secret: str = "",
    db: AsyncSession = Depends(get_db),
):
    if not secrets.compare_digest(secret, settings.CRON_SECRET):
        raise HTTPException(status_code=403, detail="Invalid cron secret")
    
    result = await run_daily_sync(db, max_new=20)
    return {"status": "completed", **result}


@app.post("/api/refresh")
async def manual_refresh(
    secret: str = "",
    max_refresh: int = 10,
    background_tasks: BackgroundTasks = None,
):
    if not secrets.compare_digest(secret, settings.CRON_SECRET):
        raise HTTPException(status_code=403, detail="Invalid secret")
    
    background_tasks.add_task(_refresh_background, max_refresh)
    return {"status": "started", "max_refresh": max_refresh}


async def _refresh_background(max_refresh: int):
    from app.database import async_session
    from app.jobs.daily_sync import smart_refresh
    
    async with async_session() as db:
        try:
            result = await smart_refresh(db, max_refresh=max_refresh)
            logger.info(f"ğŸ”„ Manual refresh result: {result}")
        except Exception as e:
            logger.error(f"âŒ Manual refresh failed: {e}")


# â”€â”€â”€ Seed Endpoint (dev only) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@app.post("/api/seed")
async def seed_database(
    count: int = 50,
    secret: str = "",
    db: AsyncSession = Depends(get_db),
):
    if not secrets.compare_digest(secret, settings.CRON_SECRET):
        raise HTTPException(status_code=403, detail="Invalid secret")

    result = await run_daily_sync(db, max_new=count)
    return {"status": "seeded", **result}


# â”€â”€â”€ Delete Movie Endpoint (Maintenance) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@app.delete("/api/movies/{tmdb_id}")
async def delete_movie(
    tmdb_id: int,
    secret: str = "",
    db: AsyncSession = Depends(get_db),
):
    if not secrets.compare_digest(secret, settings.CRON_SECRET):
        raise HTTPException(status_code=403, detail="Invalid secret")
    
    result = await db.execute(
        select(Movie).where(Movie.tmdb_id == tmdb_id)
    )
    movie = result.scalar_one_or_none()
    if not movie:
        raise HTTPException(status_code=404, detail="Movie not found")
    
    title = movie.title
    await db.delete(movie)
    await db.commit()
    return {"status": "deleted", "title": title, "tmdb_id": tmdb_id}


# â”€â”€â”€ Regenerate Endpoint (Maintenance) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# OOM FIX: Processes in batches of 20 with gc.collect() between batches.
# Each batch opens its own DB session and closes it when done.
# This keeps memory usage under 512MB on Koyeb free tier.

REGEN_BATCH_SIZE = 20

@app.post("/api/regenerate")
async def regenerate_all_reviews(
    secret: str = "",
    background_tasks: BackgroundTasks = None,
    db: AsyncSession = Depends(get_db),
):
    """Re-generate all existing reviews with the current prompt."""
    if not secrets.compare_digest(secret, settings.CRON_SECRET):
        raise HTTPException(status_code=403, detail="Invalid secret")

    from sqlalchemy.orm import joinedload

    result = await db.execute(
        select(Movie).options(joinedload(Movie.review))
    )
    all_movies = result.unique().scalars().all()
    movies_with_reviews = [m for m in all_movies if m.review is not None]
    tmdb_ids = [m.tmdb_id for m in movies_with_reviews]

    background_tasks.add_task(_regenerate_background, tmdb_ids)

    return {
        "status": "started",
        "message": f"Regenerating {len(tmdb_ids)} reviews in batches of {REGEN_BATCH_SIZE}. Watch server logs.",
        "count": len(tmdb_ids),
    }


async def _regenerate_background(tmdb_ids: list[int]):
    """
    Background task: regenerate reviews in batches.
    Each batch gets its own DB session which is closed after the batch.
    gc.collect() runs between batches to free memory.
    This prevents OOM on 512MB Koyeb instances.
    """
    from app.database import async_session
    from app.services.pipeline import generate_review_for_movie

    total = len(tmdb_ids)
    regenerated = 0
    failed = 0

    logger.info(f"ğŸ”„ Regeneration started: {total} movies in batches of {REGEN_BATCH_SIZE}")

    for batch_start in range(0, total, REGEN_BATCH_SIZE):
        batch = tmdb_ids[batch_start:batch_start + REGEN_BATCH_SIZE]
        batch_num = batch_start // REGEN_BATCH_SIZE + 1
        total_batches = (total + REGEN_BATCH_SIZE - 1) // REGEN_BATCH_SIZE

        logger.info(f"ğŸ“¦ Batch {batch_num}/{total_batches} â€” processing {len(batch)} movies")

        for tmdb_id in batch:
            # Each movie gets its own session to avoid session bloat
            async with async_session() as db:
                try:
                    result = await db.execute(
                        select(Movie).where(Movie.tmdb_id == tmdb_id)
                    )
                    movie = result.scalar_one_or_none()
                    if movie:
                        logger.info(f"â™»ï¸ [{regenerated + failed + 1}/{total}] Regenerating: {movie.title}")
                        await generate_review_for_movie(db, movie)
                        await db.commit()
                        regenerated += 1
                except Exception as e:
                    await db.rollback()
                    failed += 1
                    logger.error(f"âŒ Failed tmdb_id {tmdb_id}: {e}")

        # Free memory between batches
        gc.collect()
        logger.info(f"âœ… Batch {batch_num}/{total_batches} done. Memory freed. Progress: {regenerated} success, {failed} failed")

    logger.info(f"ğŸ Regeneration complete: {regenerated} success, {failed} failed out of {total}")


# â”€â”€â”€ Seed Top-Rated Endpoint â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@app.post("/api/seed-top-rated")
async def seed_top_rated(
    pages: int = 10,
    media_type: str = "movie",
    secret: str = "",
    background_tasks: BackgroundTasks = None,
):
    if not secrets.compare_digest(secret, settings.CRON_SECRET):
        raise HTTPException(status_code=403, detail="Invalid secret")
    
    if media_type not in ("movie", "tv"):
        raise HTTPException(status_code=400, detail="media_type must be 'movie' or 'tv'")
    
    pages = min(max(pages, 1), 20)
    
    background_tasks.add_task(_seed_top_rated_background, pages, media_type)
    return {
        "status": "started",
        "message": f"Seeding ~{pages * 20} top-rated {media_type}s in background. Watch server logs.",
    }


async def _seed_top_rated_background(pages: int, media_type: str):
    from app.database import async_session
    from app.services.tmdb import tmdb_service
    from app.services.pipeline import get_or_create_movie, generate_review_for_movie
    
    try:
        generated = 0
        skipped = 0
        failed = 0
        
        for page in range(1, pages + 1):
            try:
                if media_type == "movie":
                    results = await tmdb_service.get_top_rated_movies(page)
                else:
                    results = await tmdb_service.get_top_rated_tv(page)
                
                for item in results:
                    tmdb_id = item["id"]
                    title = item.get("title") or item.get("name", "Unknown")
                    
                    async with async_session() as db:
                        existing = await db.execute(
                            select(Movie).where(Movie.tmdb_id == tmdb_id)
                        )
                        if existing.scalar_one_or_none():
                            skipped += 1
                            continue
                        
                        try:
                            movie = await get_or_create_movie(db, tmdb_id, media_type)
                            await generate_review_for_movie(db, movie)
                            await db.commit()
                            generated += 1
                            logger.info(f"â­ [{generated}] Top rated {media_type}: {title}")
                        except Exception as e:
                            await db.rollback()
                            failed += 1
                            logger.error(f"âŒ Failed: {title} â€” {e}")
                
                # Free memory after each page
                gc.collect()
                            
            except Exception as e:
                logger.error(f"âŒ Failed to fetch page {page}: {e}")
        
        logger.info(f"ğŸ Top rated seed complete: {generated} new, {skipped} skipped, {failed} failed")
    except Exception as e:
        logger.critical(f"ğŸš¨ Seed top rated task crashed: {e}")